{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nmt.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrmDPH_X8tWs",
        "colab_type": "text"
      },
      "source": [
        "In this project we train a sequence to sequence neural network with attention mechanism to translate from Hindi to English. This project heavily draws from this [tutorial](https://https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html) Their data selection and filtering methodology is immensely helpful, and allows us to focus more on the model architecture and easily going from problem formulation to the code.\n",
        "\n",
        "For the hindi-english sentence pairs we use:\n",
        "1.   Tatoeba Project (Downloaded from http://www.manythings.org/anki/)\n",
        "2.   HindEnCorp 0.5 corpus (Downloaded from https://lindat.mff.cuni.cz/repository/xmlui/handle/11858/00-097C-0000-0023-625F-0).\n",
        "\n",
        "The preprocessing steps for HindEnCorp0.5 to create an eng-hin.txt file in the sentence-pair style of the tatoeba datasets used in this notebook is provided as hindencorp-pre.ipynb in this repo.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7tYDDIRX8fq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyOfc-mKX_Pp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "MAX_LENGTH = 30"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wjf82CHG7mqh",
        "colab_type": "text"
      },
      "source": [
        "A one-hot vector is used to represent each eord in the chosen language. A unique index per word will be required later to denote the input and target words.\n",
        "\n",
        "The helper class Lang has word2index and index2word dictionaries to help keep track of this, along with a count of each word to later help replace the rarer words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esfzLrqAYEHj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmIjipYvYHy5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Turn a Unicode string to plain ASCII\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZclEaigYK7n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def readLangs(lang1, lang2, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "\n",
        "    print(lang1, lang2)\n",
        "    # Read the file and split into lines\n",
        "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
        "        read().strip().split('\\n')\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(l.split('\\t')[0]), l.split('\\t')[1]] for l in lines]\n",
        "\n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAIvtmycYUST",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs]\n",
        "\n",
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPa0BL75YYhn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)\n",
        "\n",
        "teacher_forcing_ratio = 0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "memGoJWT7NjN",
        "colab_type": "text"
      },
      "source": [
        "A sequence-to-sequence network consisting of an GRU/LSTM encoder and decoder is commonly used to perform machine translation. \n",
        "The encoder network condenses an input sequence into a vector, and a decoder network unfolds that vector into a new sequence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkiKpKvKYbJM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgAokU8WCGoN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGHVltIw56X7",
        "colab_type": "text"
      },
      "source": [
        "The attention mechanism can be used to improve the existing model. Attention allows the decoder to learn to 'focus' on a specific parts of the encoder's outputs for every step of the decoder's outputs.\n",
        "\n",
        "First, attention weights are calculated, which are then multiplied by the encoder output vectors to produce a weighted combination. The result should contain information about that specific part of the input sequence, and thus help the decoder choose the right output words.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnAxgrUiYguB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zu8f739P5PhV",
        "colab_type": "text"
      },
      "source": [
        "For training we use Cross Entropy Loss with stochastic gradient descent. \n",
        "\n",
        "Using the real target outputs as the next step input instead of the decoder's guess is known as “Teacher forcing” which helps the model learn better when used in judiciously.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNWPQCErYkPb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pV-0a3kYoaj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
        "    \n",
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DujFXdyF45Bo",
        "colab_type": "text"
      },
      "source": [
        "For evaluation, we feed the decoder's predictions back to itself at each step because there are no explicit targets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7Rxp4GhZIJj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            # Change code for decoder here too\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]\n",
        "\n",
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qycHHQWNZL38",
        "colab_type": "code",
        "outputId": "0620cd0c-8e7e-456b-e0cc-5e1d3dde0752",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "input_lang, output_lang, pairs = prepareData('eng', 'hin', True)\n",
        "x = random.choice(pairs)\n",
        "print(x[0])\n",
        "print(x[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading lines...\n",
            "eng hin\n",
            "Read 2810 sentence pairs\n",
            "Trimmed to 2810 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "hin 3138\n",
            "eng 2336\n",
            "मुझे अपनी एक अटैची मिल नहीं रही है।\n",
            "one of my bags is missing .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxydM7WGZcLm",
        "colab_type": "code",
        "outputId": "0b302119-f9d3-478a-bd6b-9d0c024c54cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941
        }
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "hidden_size = 256\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "\n",
        "decoder = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
        "decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "trainIters(encoder1, decoder1, 75000, print_every=5000)\n",
        "evaluateRandomly(encoder1, decoder1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2m 20s (- 32m 42s) (5000 6%) 4.2188\n",
            "4m 39s (- 30m 13s) (10000 13%) 3.5171\n",
            "6m 59s (- 27m 58s) (15000 20%) 2.8804\n",
            "9m 20s (- 25m 41s) (20000 26%) 2.2460\n",
            "11m 41s (- 23m 23s) (25000 33%) 1.7578\n",
            "14m 3s (- 21m 5s) (30000 40%) 1.3251\n",
            "16m 27s (- 18m 48s) (35000 46%) 1.0170\n",
            "18m 51s (- 16m 29s) (40000 53%) 0.7182\n",
            "21m 14s (- 14m 9s) (45000 60%) 0.4965\n",
            "23m 39s (- 11m 49s) (50000 66%) 0.3297\n",
            "26m 2s (- 9m 28s) (55000 73%) 0.2475\n",
            "28m 27s (- 7m 6s) (60000 80%) 0.1626\n",
            "30m 50s (- 4m 44s) (65000 86%) 0.1351\n",
            "33m 14s (- 2m 22s) (70000 93%) 0.0969\n",
            "35m 39s (- 0m 0s) (75000 100%) 0.0779\n",
            "> उसकी मदद के बिना तुम नहीं कर पाते।\n",
            "= if it had not been for her help you would never have done it .\n",
            "< if it had not been for her help you would never have done it . <EOS>\n",
            "\n",
            "> दो लड़के कमरे से भागे निकल आए।\n",
            "= two boys came running out of the room .\n",
            "< two boys came running out of the room . <EOS>\n",
            "\n",
            "> स्कूल अप्रैल में शुरू होता है।\n",
            "= school begins in april .\n",
            "< school begins in april . <EOS>\n",
            "\n",
            "> तुम अच्छे से सोये क्या?\n",
            "= did you sleep well ?\n",
            "< did you sleep well ? <EOS>\n",
            "\n",
            "> मैं आपकी मदद के लिए बहुत आभारी हूँ।\n",
            "= i am much obliged to you for your help .\n",
            "< i am much obliged to you for your help . <EOS>\n",
            "\n",
            "> उसने कहा कि वह खुश थी।\n",
            "= she said that she was happy .\n",
            "< she said that she was happy . <EOS>\n",
            "\n",
            "> तुम अगले महीने अम्रीका जाओगे क्या?\n",
            "= will you go to america next month ?\n",
            "< will you go to america next month ? <EOS>\n",
            "\n",
            "> मुझे गर्मी का मौसम पसंद नहीं है।\n",
            "= i don t like summer .\n",
            "< i don t like summer . <EOS>\n",
            "\n",
            "> मैं उसे पहचानता हूँ पर मैं उससे कभी मिला नहीं हूँ।\n",
            "= i ve never met her but i recognize her .\n",
            "< i ve never met him but i recognize him . <EOS>\n",
            "\n",
            "> वह पुलिस अफ़सर बन गया।\n",
            "= he became a policeman .\n",
            "< he became a policeman . . <EOS>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGy6Mk-faLqt",
        "colab_type": "code",
        "outputId": "1d7349da-d3f0-4c5c-a2c0-fcfa01d00ebf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        }
      },
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline  \n",
        "import matplotlib.ticker as ticker\n",
        "import matplotlib.font_manager as font_manager\n",
        "import numpy as np\n",
        "\n",
        "def evaluateAndShowAttention(input_sentence):\n",
        "  \n",
        "    prop = font_manager.FontProperties(fname='data/Kruti_Dev_010.ttf')\n",
        "    prop.set_weight = 'light'\n",
        "    mpl.rcParams['font.family'] = prop.get_name()\n",
        "    mpl.rcParams['font.weight'] = 'light'\n",
        "    \n",
        "    output_words, attentions = evaluate(\n",
        "        encoder1, decoder1, input_sentence)\n",
        "    print('input =', input_sentence)\n",
        "    print('output =', ' '.join(output_words))\n",
        "    showAttention(input_sentence, output_words, attentions)\n",
        "    plt.show(attentions.numpy())\n",
        "    \n",
        "evaluateAndShowAttention('हम वहाँ तीन बार खा चुके हैं।')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input = हम वहाँ तीन बार खा चुके हैं।\n",
            "output = we have eaten there three times . <EOS>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhsAAAI1CAYAAAB/gTj7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBm94AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1440x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-0b1e0b1d9631>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattentions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mevaluateAndShowAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'हम वहाँ तीन बार खा चुके हैं।'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-28-0b1e0b1d9631>\u001b[0m in \u001b[0;36mevaluateAndShowAttention\u001b[0;34m(input_sentence)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output ='\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mshowAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattentions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattentions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mevaluateAndShowAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'हम वहाँ तीन बार खा चुके हैं।'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    252\u001b[0m     \"\"\"\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# only call close('all') if any to close\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# close triggers gc.collect, which can be slow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mclose\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mGcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_fig_managers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'all'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDumXns76qm8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}